# -*- coding: utf-8 -*-
"""FuzzyKMeansPP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TtGwckDZ0apJM_BKQaFr9BFuwwaOLNLc
"""

import sys
import numpy as np
from numpy.random import seed
import math
seed(12)

def eud(ss, dd):
  b = (ss-dd) * (ss - dd)
  su = 0
  for i in range(len(b)):
    su += b[i]
  return np.sqrt(su)

def qerror_hard_cluster(k, X, y):
  res = 0
  for i in range(1, k+1):
    a = []
    for index in range(len(y)):
      if(y[index] == i):
        a.append(X[index])
    a_su = sum(a)
    a_mean = a_su/max(len(a), 1)
    dist = []
    for j in a:
      dist.append((j-a_mean)**2)
    for d in dist:
      res += sum(d)
  return res

def qerror_soft_cluster(k, X, mem_matrix, cluster_centers):
  res = 0
  for i in range(len(X)):
    for j in range(k):
      res += mem_matrix[i][j] * np.linalg.norm(X[i] - cluster_centers[j])**2
  return res

class IrisFuzzyKmeansPP:
  def __init__(self, X, k, r, m):
    self.X = X
    self.k = k
    self.r = r
    self.m = m
    self.n_rows, self.n_cols = X.shape
    self.k_clusters = None
    self.mem_matrix = None

  def _init_k_random_centers_pp(self):  
    self.k_centers = []
    for i in range(k):
      if i == 0:
        first_random_index = np.random.choice(self.n_rows, 1, replace=False)
        for random_index in first_random_index:
          self.k_centers.append(self.X[random_index])
      else:
        center_distances = []
        for index in range(self.n_rows):
          minimum_distance = math.inf
          for existing_center in range(len(self.k_centers)):
            current_dist = eud(self.X[index], self.k_centers[existing_center])
            if(minimum_distance > current_dist):
              minimum_distance = current_dist
          center_distances.append(minimum_distance)
        su = -1 * math.inf
        datapoint_index = None
        for cd in range(len(center_distances)):
          if(center_distances[cd] > su):
            su = center_distances[cd]
            datapoint_index = cd
        self.k_centers.append(self.X[datapoint_index, :])
  
  def _init_mem_matrix(self):
    self.mem_matrix = list()
    for i in range(self.n_rows):
      empty_list = [None for x in range(self.k)]
      self.mem_matrix.append(empty_list)
  
  def _get_mem_matrix(self):
    fuzzy_r=float(2/(self.m-1))
    for i in range(self.n_rows):
      d_from_centers = []
      for j in range(self.k):
        d_from_centers.append(eud(self.X[i], self.k_centers[j]))
      for j in range(self.k):
        temp = []
        for q in range(self.k):
          temp.append(float(d_from_centers[j]/max(d_from_centers[q], 1))**fuzzy_r)
        den = sum(temp)
        self.mem_matrix[i][j] = float(1/max(den, 1))

  def _get_k_hard_clusters(self):
    self.k_clusters=[]
    for i in range(self.n_rows):
      su = -1 * math.inf
      ans = None
      for c in range(len(self.mem_matrix[i])):
        if(self.mem_matrix[i][c] > su):
          su = self.mem_matrix[i][c]
          ans = c
      self.k_clusters.append(ans)

  def run(self):
    self._init_k_random_centers_pp()
    self._init_mem_matrix()
    for i in range(self.r):
      self._get_mem_matrix()
    self._get_k_hard_clusters()
    return self.k_clusters, self.k_centers, self.mem_matrix

if __name__ == "__main__":
  X = np.loadtxt(sys.argv[1], delimiter=',')
  k = int(sys.argv[2])
  r = int(sys.argv[3])
  p = int(sys.argv[4])
  output_file = sys.argv[5]
  iris_kmeans_pp = IrisFuzzyKmeansPP(X, k, r)
  clusters, centers, mem_matrix = iris_kmeans_pp.run()
  np.savetxt(output_file, y, delimiter=',')
  print("Quantization error for Fuzzy KMeansPP clustering", qerror_soft_cluster(k, X, mem_matrix, centers))
  print("Quantization error for Hard Clusters", qerror_hard_cluster(k, X, clusters))

X = np.loadtxt('./iris-data.csv', delimiter=',')
k = 3
r = 10
p = 5
iris_kmeans_pp = IrisFuzzyKmeansPP(X, k, r, p)
clusters, centers, mem_matrix = iris_kmeans_pp.run()

mem_matrix

clusters

qerror_hard_cluster(k, X, clusters)

def error(a,b):
  su = 0
  for i in range(len(a)):
    su += (a[i]-b[i]) ** 2
  return su/150
ydash = np.loadtxt('./iris-labels.csv', delimiter=',')

error(clusters, ydash)

error(clusters, ydash)

